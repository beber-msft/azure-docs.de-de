---
title: 'Formularerkennung: Allgemeines Dokumentmodell | Vorschau'
titleSuffix: Azure Applied AI Services
description: Konzepte, die Datenextraktion und -analyse mithilfe eines vordefinierten allgemeinen Dokumentenvorschaumodells umfassen
author: vkurpad
manager: nitinme
ms.service: applied-ai-services
ms.subservice: forms-recognizer
ms.topic: conceptual
ms.date: 10/07/2021
ms.author: lajanuar
recommendations: false
ms.custom: ignite-fall-2021
ms.openlocfilehash: 63d381f96a9781f2f3ab1abfd45d03c968d6dad8
ms.sourcegitcommit: 106f5c9fa5c6d3498dd1cfe63181a7ed4125ae6d
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 11/02/2021
ms.locfileid: "131027517"
---
<!-- markdownlint-disable MD033 -->

# <a name="form-recognizer-general-document-model-preview"></a>Formularerkennung: Allgemeines Dokumentmodell (Vorschau)

Das allgemeine Dokumentenvorschaumodell kombiniert leistungsstarke OCR-Funktionen (optische Zeichenerkennung) mit Deep Learning-Modellen zur Extraktion von Schl√ºssel-Wert-Paaren und Entit√§ten aus Dokumenten. Allgemeines Dokument ist nur mit der Vorschau-API (v3.0) verf√ºgbar.  Weitere Informationen zur Verwendung der Vorschau-API (v3.0) finden Sie in unserem [Migrationsleitfaden](v3-migration-guide.md).

Die allgemeine Dokumenten-API unterst√ºtzt die meisten Formulartypen, analysiert Ihre Dokumente und ordnet Werte den von ihr gefundenen Schl√ºsseln und Eintr√§gen in Tabellen zu. Sie eignet sich ideal f√ºr die Extraktion g√§ngiger Schl√ºssel-Werte-Paare aus Dokumenten. Sie k√∂nnen das allgemeine Dokumentenmodell als Alternative zum [Trainieren eines benutzerdefinierten Modells ohne Bezeichnungen](compose-custom-models.md#train-without-labels) verwenden.

## <a name="general-document-features"></a>Allgemeine Dokumentfeatures

* Es ist nicht erforderlich, ein benutzerdefiniertes Modell zum Extrahieren von Schl√ºssel-Wert-Paaren zu trainieren.

* Eine einzelne API wird verwendet, um Schl√ºssel-Wert-Paar, Entit√§ten, Text, Tabellen und Strukturen aus Dokumenten zu extrahieren.

* Es handelt sich um ein vortrainiertes Modell, das regelm√§√üig mit neuen Daten trainiert wird, um die Abdeckung und Genauigkeit zu verbessern.

* Das allgemeine Dokumentmodell unterst√ºtzt strukturierte, teilweise strukturierte und unstrukturierte Daten.

***Mit Formularerkennung Studio verarbeitetes Beispieldokument***

:::image type="content" source="media/studio/general-document-analyze.png" alt-text="Screenshot: Allgemeine Dokumentenanalyse in Formularerkennung Studio":::

## <a name="development-options"></a>Entwicklungsoptionen

Die folgenden Ressourcen werden von der Azure-Formularerkennung v3.0 unterst√ºtzt:

| Funktion | Ressourcen |
|----------|-------------------------|
|üÜï **Allgemeines Dokumentmodell**|<ul ><li>[**Formularerkennung Studio**](https://formrecognizer.appliedai.azure.com)</li><li>[**REST-API**](https://westus.dev.cognitive.microsoft.com/docs/services/form-recognizer-api-v3-0-preview-1/operations/AnalyzeDocument)</li><li>[**C# SDK**](quickstarts/try-v3-csharp-sdk.md)</li><li>[**Python SDK**](quickstarts/try-v3-python-sdk.md)</li><li>[**Java SDK**](quickstarts/try-v3-java-sdk.md)</li><li>[**JavaScript SDK**](quickstarts/try-v3-javascript-sdk.md)</li></ul>|

### <a name="try-form-recognizer"></a>Formularerkennung ausprobieren

Erfahren Sie, wie Daten, einschlie√ülich Tabellen, Werte und Entit√§ten, aus Formularen und Dokumenten mithilfe von Formularerkennung Studio oder unserem Beispielbeschriftungstool extrahiert werden. Sie ben√∂tigen Folgendes:

* Azure-Abonnement ‚Äì Sie k√∂nnen ein [kostenloses Abonnement erstellen](https://azure.microsoft.com/free/cognitive-services/)

* Eine [Formularerkennungsinstanz](https://ms.portal.azure.com/#create/Microsoft.CognitiveServicesFormRecognizer) im Azure-Portal Sie k√∂nnen den kostenlosen Tarif (`F0`) verwenden, um den Dienst auszuprobieren. W√§hlen Sie nach der Bereitstellung Ihrer Ressource **Zu Ressource wechseln** aus, um Ihren API-Schl√ºssel und -Endpunkt abzurufen.

 :::image type="content" source="media/containers/keys-and-endpoint.png" alt-text="Screenshot: Schl√ºssel und Endpunktspeicherort im Azure-Portal":::

#### <a name="form-recognizer-studio-preview"></a>Formularerkennung Studio (Vorschau)

> [!NOTE]
> Formularerkennung Studio und das allgemeine Dokumentmodell sind mit der Vorschau-API (v3.0) verf√ºgbar.

1. W√§hlen Sie auf der Startseite von Formularerkennung Studio die Option **Allgemeine Dokumente** aus.

1. Sie k√∂nnen entweder das Beispieldokument analysieren oder die Schaltfl√§che **+ Hinzuf√ºgen** ausw√§hlen, um Ihr eigenes Beispiel hochzuladen.

1. W√§hlen Sie die Schaltfl√§che **Analysieren** aus:

    :::image type="content" source="media/studio/general-document-analyze-1.png" alt-text="Screenshot: Men√º ‚ÄûAllgemeines Dokument analysieren‚Äú":::

    > [!div class="nextstepaction"]
    > [Ausprobieren von Formularerkennung Studio](https://formrecognizer.appliedai.azure.com/studio/prebuilt?formType=document)

## <a name="key-value-pairs"></a>Schl√ºssel-Wert-Paare

Schl√ºssel-Wert-Paare sind bestimmte Bereiche innerhalb des Dokuments, die eine Bezeichnung oder einen Schl√ºssel und die zugeh√∂rige Antwort oder den zugeh√∂rigen Wert identifizieren. In einer strukturierten Form kann dies die Bezeichnung und der Wert sein, den der Benutzer f√ºr dieses Feld eingegeben hat. In einem unstrukturierten Dokument kann es sich um das Datum handeln, an dem ein Vertrag basierend auf dem Text in einem Absatz ausgef√ºhrt wurde.  Das KI-Modell wird trainiert, um identifizierbare Schl√ºssel und Werte basierend auf einer Vielzahl von Dokumenttypen, Formaten und Strukturen zu extrahieren.

Schl√ºssel k√∂nnen auch isoliert existieren, wenn das Modell feststellt, dass ein Schl√ºssel ohne zugeh√∂rigen Wert vorhanden ist, oder wenn optionale Felder verarbeitet werden. Beispielsweise kann ein Feld f√ºr den zweiten Vornamen in einigen F√§llen in einem Formular leer gelassen werden. Schl√ºssel-Wert-Paare sind immer Textabschnitte, die im Dokument enthalten sind. Wenn Sie Dokumente besitzen, in denen derselbe Wert auf unterschiedliche Weise beschrieben wird, z.¬†B. ein Kunde oder ein Benutzer, ist der zugeordnete Schl√ºssel basierend auf dem Dokumentinhalt entweder ‚ÄûKunde‚Äú oder ‚ÄûBenutzer‚Äú. 

## <a name="entities"></a>Entit√§ten

Modelle f√ºr die Verarbeitung nat√ºrlicher Sprache k√∂nnen Teile der Sprache identifizieren und jedes Token oder Wort klassifizieren. Das Erkennungsmodell f√ºr benannte Entit√§ten kann Entit√§ten wie Personen, Standorte und Datumsangaben identifizieren, um eine umfassendere Erfahrung zu erm√∂glichen. Durch das Identifizieren von Entit√§ten k√∂nnen Sie zwischen Kundentypen unterscheiden, z.¬†B. Einzelperson oder Organisation.
Das Schl√ºssel-Wert-Paar-Extraktionsmodell und das Modell zur Identifikation von Entit√§ten werden parallel f√ºr das gesamte Dokument und nicht nur f√ºr die Werte der extrahierten Schl√ºssel-Wert-Paare ausgef√ºhrt. Dadurch wird sichergestellt, dass komplexe Strukturen, bei denen ein Schl√ºssel nicht identifiziert werden kann, weiterhin angereichert werden, indem die Entit√§ten identifiziert werden, auf die verwiesen wird. Sie k√∂nnen weiterhin Schl√ºssel oder Werte mit Entit√§ten abgleichen, die auf den Offsets der identifizierten Spannen basieren.

* Das allgemeine Dokumentenmodell ist ein vortrainiertes Modell und kann direkt √ºber die REST-API aufgerufen werden. 

* Das allgemeine Dokumentenmodell unterst√ºtzt Named Entity Recognition (NER) f√ºr verschiedene Entit√§tskategorien. NER ist die F√§higkeit, verschiedene Entit√§ten im Text zu identifizieren und sie in vordefinierte Klassen oder Typen zu kategorisieren. Beispiel: Person, Ort, Ereignis, Produkt und Organisation. Die Extraktion von Entit√§ten kann in Szenarien n√ºtzlich sein, in denen Sie die extrahierten Werte √ºberpr√ºfen m√∂chten. Die Entit√§ten werden aus dem gesamten Inhalt und nicht nur aus den extrahierten Werten extrahiert.

## <a name="general-document-model-data-extraction"></a>Datenextraktion f√ºr das allgemeine Dokumentmodell

| **Modell**   | **Textextraktion** |**Schl√ºssel-Werte-Paare** |**Auswahlmarkierungen**   | **Tabellen**   |**Entit√§ten** |
| --- | :---: |:---:| :---: | :---: |:---: |
|Allgemeines Dokument  | ‚úì  |  ‚úì | ‚úì  | ‚úì  | ‚úì  |

## <a name="input-requirements"></a>Eingabeanforderungen

* Die besten Ergebnisse erzielen Sie, wenn Sie pro Dokument ein deutliches Foto oder einen hochwertigen Scan bereitstellen.
* Unterst√ºtzte Dateiformate: JPEG, PNG, BMP, TIFF und PDF (in Text eingebettet oder gescannt). In Text eingebettete PDF-Dateien sind am besten geeignet, um die M√∂glichkeit von Fehlern beim Extrahieren und Auffinden von Zeichen auszuschlie√üen.
* In den Formaten PDF und TIFF k√∂nnen bis zu 2.000 Seiten verarbeitet werden (bei einem kostenlosen Abonnement werden nur die ersten beiden Seiten verarbeitet).
* Die Dateigr√∂√üe muss unter 50¬†MB liegen.
* Bei Bildern m√ºssen die Abmessungen zwischen 50 √ó 50 Pixel und 10.000 √ó 10.000 Pixel liegen.
* Die PDF-Abmessungen sind bis zu 17¬†√ó¬†17¬†Zoll, sodass die Papierformate Legal oder A3 hineinpassen, oder kleiner.
* Der Gesamtumfang der Trainingsdaten betr√§gt 500 Seiten oder weniger.
* Wenn Ihre PDFs kennwortgesch√ºtzt sind, m√ºssen Sie die Sperre vor dem Senden entfernen.
* F√ºr unbeaufsichtigtes Lernen (ohne beschriftete Daten) gilt Folgendes:
  * Die Daten m√ºssen Schl√ºssel und Werte enthalten.
  * Die Schl√ºssel m√ºssen √ºber oder links von den Werten stehen; sie d√ºrfen nicht unter oder rechts von ihnen stehen.

## <a name="supported-languages-and-locales"></a>Unterst√ºtzte Sprachen und Gebietsschemas

| Modell | Sprache ‚Äì Gebietsschemacode | Standard |
|--------|:----------------------|:---------|
|Allgemeines Dokument| <ul><li>Englisch (USA) ‚Äì en-US</li></ul>| Englisch (USA) ‚Äì en-US|

### <a name="named-entity-recognition-ner-categories"></a>NER-Kategorien (Erkennung benannter Entit√§ten)

| Category | type | BESCHREIBUNG |
|-----------|-------|--------------------|
| Person | String | Der partielle oder vollst√§ndige Name einer Person. |
| PersonType | String | Der Auftragstyp oder die Rolle einer Person.  |
| Standort | String | nat√ºrliche und von Menschen hergestellte Wahrzeichen, Geb√§ude, geografische Merkmale und geopolitische Entit√§ten |
| Organization | String | Firmen, politische Gruppen, Musikgruppen, Sportvereine, Regierungsstellen und √∂ffentliche Organisationen |
| Ereignis | String | Historische Ereignisse, gesellschaftliche Ereignisse und Naturereignisse |
| Produkt | String |Physische Objekte verschiedener Kategorien. |
| Skill | String | Eine Funktion, Kenntnis oder ein Fachwissen |
| Adresse | Zeichenfolge | Vollst√§ndige Postanschrift |
| Telefonnummer | String| Telefonnummern | 
| Email | String | E-Mail-Adresse. |
| URL | String | Website-URLs und -Links |
| IP-Adresse | String | Netzwerk-IP-Adressen |
| Datetime | String | Datums- und Uhrzeitangaben |
| Menge | String | numerische Messungen und Einheiten |

## <a name="considerations"></a>√úberlegungen

* Die Extraktion von Entit√§ten kann in Szenarien n√ºtzlich sein, in denen Sie die extrahierten Werte √ºberpr√ºfen m√∂chten. Die Entit√§ten werden f√ºr den gesamten Inhalt der Dokumente extrahiert, nicht nur f√ºr die extrahierten Werte.

* Schl√ºssel sind Ausschnitte von Text, der aus dem Dokument extrahiert wurde. F√ºr teilweise strukturierte Dokumente m√ºssen Schl√ºssel m√∂glicherweise einem vorhandenen Schl√ºsselw√∂rterbuch zugeordnet werden.

* Erwarten Sie, dass Schl√ºssel-Wert-Paare mit einem Schl√ºssel, aber ohne Wert angezeigt werden. Wenn ein Benutzer z.¬†B. keine E-Mail-Adresse in das Formular eingeben m√∂chte.

## <a name="next-steps"></a>N√§chste Schritte

* Erfahren Sie, wie Sie die Vorschauversion in Ihren Anwendungen und Workflows verwenden k√∂nnen, indem Sie unseren [**Formularerkennung v3.0-Migrationsleitfaden**](v3-migration-guide.md) befolgen.

* Erkunden Sie die [**REST-API (Vorschau)**](https://westus.dev.cognitive.microsoft.com/docs/services/form-recognizer-api-v3-0-preview-1/operations/AnalyzeDocument), um mehr √ºber die Vorschauversion und neue Funktionen zu erfahren.

> [!div class="nextstepaction"]
> [Ausprobieren von Formularerkennung Studio](https://formrecognizer.appliedai.azure.com/studio)
